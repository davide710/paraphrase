{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11284104,"sourceType":"datasetVersion","datasetId":7055154}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install unsloth vllm\n!pip install --no-deps git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:25:43.463291Z","iopub.execute_input":"2025-04-09T10:25:43.463534Z","iopub.status.idle":"2025-04-09T10:30:18.601500Z","shell.execute_reply.started":"2025-04-09T10:25:43.463511Z","shell.execute_reply":"2025-04-09T10:30:18.600536Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from unsloth import FastModel\nimport torch\n\nmodel, tokenizer = FastModel.from_pretrained(\n    model_name=\"unsloth/gemma-3-1b-it-unsloth-bnb-4bit\",\n    max_seq_length=2048,\n    load_in_4bit=True,\n    load_in_8bit=False,\n    full_finetuning=False,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:30:18.602444Z","iopub.execute_input":"2025-04-09T10:30:18.602710Z","iopub.status.idle":"2025-04-09T10:31:06.231123Z","shell.execute_reply.started":"2025-04-09T10:30:18.602688Z","shell.execute_reply":"2025-04-09T10:31:06.230191Z"}},"outputs":[{"name":"stdout","text":"ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\nðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\nINFO 04-09 10:30:45 [__init__.py:239] Automatically detected platform cuda.\n==((====))==  Unsloth 2025.3.19: Fast Gemma3 patching. Transformers: 4.50.0.dev0. vLLM: 0.8.3.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post2. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\nUnsloth: Using float16 precision for gemma3 won't work! Using float32.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a964cfa84b648349a811b56f8392c21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fcbb13d01df412f961c9a06c029dbc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"458659ca4682497c8f2e5263b0e8a876"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ac2b32ea0c8488787c221719076c756"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a98978443700490dbca157eff4877266"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32253e5de0534c179f6acfe20b903305"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/670 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4f1f4f56e624db2b3ea8b01ebb95cd4"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"model = FastModel.get_peft_model(\n    model,\n    finetune_vision_layers=False,\n    finetune_language_layers=True,\n    finetune_attention_modules=True,\n    finetune_mlp_modules=True,\n    r=8,\n    lora_alpha=8,\n    lora_dropout=0,\n    bias=\"none\",\n    random_state=42,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:31:06.231979Z","iopub.execute_input":"2025-04-09T10:31:06.232314Z","iopub.status.idle":"2025-04-09T10:31:11.372699Z","shell.execute_reply.started":"2025-04-09T10:31:06.232284Z","shell.execute_reply":"2025-04-09T10:31:11.371752Z"}},"outputs":[{"name":"stdout","text":"Unsloth: Making `model.base_model.model.model` require gradients\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"with open('/kaggle/input/simplified-macbeth/simplified_macbeth', 'r') as f:\n    text = f.read()\n\nlines = text.split('\\n\\n')\nwithout_name = [''.join(l.split(':')[1:])[1:] for l in lines]\noriginals = [l.split('[[')[0][:-1] for l in without_name]\ntranslated = [l.split('[[')[1].split(']]')[0] for l in without_name]\nprint(originals[115], '---->', translated[115])\n\nimport pandas as pd\nfrom datasets import Dataset\n\ndata = {\"input\": originals, \"output\": translated}\ndf = pd.DataFrame(data)\ndataset = Dataset.from_pandas(df)\n\nprompt = \"\"\"Below is an instruction on how to translate text from complex and archaic to simple and modern english.\nThe input contains this text. Write in the response a faithful translation.\n\n### Instruction:\nTranslate the following line from complex to simple english.\nIt may contain archaic and literary words or structures: make them easily understandable.\n\n### Input:\n{}\n\n### Response:\n{}\"\"\"\n\nEOS_TOKEN = tokenizer.eos_token\ndef formatting_prompts_func(data):\n    inputs = data['input']\n    outputs = data['output']\n    texts = []\n    for inp, outp in zip(inputs, outputs):\n        text = prompt.format(inp, outp) + EOS_TOKEN\n        texts.append(text)\n    return {\"text\" : texts}\n\ndataset = dataset.map(formatting_prompts_func, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:31:11.374881Z","iopub.execute_input":"2025-04-09T10:31:11.375125Z","iopub.status.idle":"2025-04-09T10:31:11.466435Z","shell.execute_reply.started":"2025-04-09T10:31:11.375105Z","shell.execute_reply":"2025-04-09T10:31:11.465411Z"}},"outputs":[{"name":"stdout","text":"We will proceed no further in this business He hath honour'd me of late; and I have bought Golden opinions from all sorts of people, Which would be worn now in their newest gloss, Not cast aside so soon. ----> We will not continue with this plan. He has honored me recently, and I have earned the respect of all kinds of people, which I want to enjoy now, not throw away so soon.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/654 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0842a821c9c4234a9cbb3924d008235"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"inputs = tokenizer(\n[\n    prompt.format(\n        \"This above all: to thine own self be true, And it must follow, as the night the day,Thou canst not then be false to any man.\",\n        \"\",\n    )\n], return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(**inputs, max_new_tokens=2048, use_cache=True)\ntokenizer.batch_decode(outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:31:11.467986Z","iopub.execute_input":"2025-04-09T10:31:11.468325Z","iopub.status.idle":"2025-04-09T10:31:48.980029Z","shell.execute_reply.started":"2025-04-09T10:31:11.468294Z","shell.execute_reply":"2025-04-09T10:31:48.978997Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[\"<bos>Below is an instruction on how to translate text from complex and archaic to simple and modern english.\\nThe input contains this text. Write in the response a faithful translation.\\n\\n### Instruction:\\nTranslate the following line from complex to simple english.\\nIt may contain archaic and literary words or structures: make them easily understandable.\\n\\n### Input:\\nThis above all: to thine own self be true, And it must follow, as the night the day,Thou canst not then be false to any man.\\n\\n### Response:\\nThis is a saying about being honest with yourself. It means that you should always be true to yourself, and that you can't be false to anyone.\\n\\n**Explanation:**\\n\\nThe translation aimed to:\\n*   Replace archaic words with simpler equivalents.\\n*   Simplify the sentence structure.\\n*   Maintain the core meaning of the original text.\\n\\nLet me know if you want me to do something else.\\n<end_of_turn>\"]"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from trl import SFTTrainer, SFTConfig\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=dataset,\n    eval_dataset=None,\n    args=SFTConfig(\n        dataset_text_field=\"text\",\n        per_device_train_batch_size=2,\n        gradient_accumulation_steps=4,\n        warmup_steps=5,\n        num_train_epochs=1,\n        learning_rate=2e-4,\n        logging_steps=1,\n        optim=\"adamw_8bit\",\n        weight_decay=0.01,\n        lr_scheduler_type=\"linear\",\n        seed=42,\n        report_to=\"none\",\n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:31:48.980967Z","iopub.execute_input":"2025-04-09T10:31:48.981342Z","iopub.status.idle":"2025-04-09T10:31:54.503857Z","shell.execute_reply.started":"2025-04-09T10:31:48.981305Z","shell.execute_reply":"2025-04-09T10:31:54.502860Z"}},"outputs":[{"name":"stdout","text":"Unsloth: Switching to float32 training since model cannot work with float16\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=4):   0%|          | 0/654 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"573d669c1a4b4040af4a1c4c34c586a0"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"gpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\nprint(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\nprint(f\"{start_gpu_memory} GB of memory reserved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:31:54.504920Z","iopub.execute_input":"2025-04-09T10:31:54.505281Z","iopub.status.idle":"2025-04-09T10:31:54.512076Z","shell.execute_reply.started":"2025-04-09T10:31:54.505248Z","shell.execute_reply":"2025-04-09T10:31:54.510826Z"}},"outputs":[{"name":"stdout","text":"GPU = Tesla T4. Max memory = 14.741 GB.\n1.512 GB of memory reserved.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:31:54.513398Z","iopub.execute_input":"2025-04-09T10:31:54.513793Z","iopub.status.idle":"2025-04-09T10:34:31.239805Z","shell.execute_reply.started":"2025-04-09T10:31:54.513753Z","shell.execute_reply":"2025-04-09T10:34:31.238970Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 654 | Num Epochs = 1 | Total steps = 41\nO^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n \"-____-\"     Trainable parameters = 6,522,880/1,000,000,000 (0.65% trained)\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [41/41 01:54, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>4.097600</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>4.090200</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4.189300</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>3.706100</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>3.799500</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>3.287500</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>3.030800</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>3.012300</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>2.983500</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.818400</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>2.729000</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>2.409900</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.891900</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.086400</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2.334700</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>2.490200</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>2.346600</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.857300</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.773200</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.728200</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>1.187800</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.629000</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>2.010300</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.360000</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.535900</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.703100</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>1.793000</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>1.570300</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>1.573000</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.052400</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>1.548400</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>1.340500</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>1.827200</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>1.688300</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>1.578200</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>1.549700</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>2.110000</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>1.450400</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>1.601000</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.304900</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>1.589300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nused_memory_for_lora = round(used_memory - start_gpu_memory, 3)\nused_percentage = round(used_memory / max_memory * 100, 3)\nlora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\nprint(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\nprint(f\"Peak reserved memory = {used_memory} GB.\")\nprint(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\nprint(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\nprint(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:34:31.240703Z","iopub.execute_input":"2025-04-09T10:34:31.241686Z","iopub.status.idle":"2025-04-09T10:34:31.248600Z","shell.execute_reply.started":"2025-04-09T10:34:31.241660Z","shell.execute_reply":"2025-04-09T10:34:31.247648Z"}},"outputs":[{"name":"stdout","text":"2.57 minutes used for training.\nPeak reserved memory = 1.559 GB.\nPeak reserved memory for training = 0.047 GB.\nPeak reserved memory % of max memory = 10.576 %.\nPeak reserved memory for training % of max memory = 0.319 %.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"FastModel.for_inference(model)\ninputs = tokenizer(\n[\n    prompt.format(\n#        \"This above all: to thine own self be true, And it must follow, as the night the day,Thou canst not then be false to any man.\",\n        \"This goodly frame, the earth, seems to me a sterile promontory, this most excellent canopy, the air, look you, this brave o'erhanging firmament, this majestical roof fretted with golden fire, why, it appears no other thing to me than a foul and pestilent congregation of vapours. What a piece of work is a man! how noble in reason! how infinite in faculty! in form and moving how express and admirable! in action how like an angel! in apprehension how like a god! the beauty of the world! the paragon of animals! And yet, to me, what is this quintessence of dust?\",    \n        \"\",\n    )\n], return_tensors=\"pt\").to(\"cuda\")\noutputs = model.generate(\n    **inputs,\n    max_new_tokens=2048,\n    temperature=1.0, top_p=0.95, top_k=64,\n)\ntokenizer.batch_decode(outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:34:31.249514Z","iopub.execute_input":"2025-04-09T10:34:31.249835Z","iopub.status.idle":"2025-04-09T10:34:47.349873Z","shell.execute_reply.started":"2025-04-09T10:34:31.249802Z","shell.execute_reply":"2025-04-09T10:34:47.349050Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[\"<bos>Below is an instruction on how to translate text from complex and archaic to simple and modern english.\\nThe input contains this text. Write in the response a faithful translation.\\n\\n### Instruction:\\nTranslate the following line from complex to simple english.\\nIt may contain archaic and literary words or structures: make them easily understandable.\\n\\n### Input:\\nThis goodly frame, the earth, seems to me a sterile promontory, this most excellent canopy, the air, look you, this brave o'erhanging firmament, this majestical roof fretted with golden fire, why, it appears no other thing to me than a foul and pestilent congregation of vapours. What a piece of work is a man! how noble in reason! how infinite in faculty! in form and moving how express and admirable! in action how like an angel! in apprehension how like a god! the beauty of the world! the paragon of animals! And yet, to me, what is this quintessence of dust?\\n\\n### Response:\\nThis beautiful frame, the earth, seems like a boring, barren place. This big, dark sky looks like a frightening, ominous roof. It seems like nothing else but a bunch of bad, smelly fumes. What a strange man! How clever! How wise! How good at making things! How good at acting! How like an angel! How good at thinking! The beauty of the world! The perfect thing! And yet, to me, it's just a pile of dust.<end_of_turn>\"]"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"model.push_to_hub('davide710/pf_gemma_1b', token='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')\ntokenizer.push_to_hub('davide710/pf_gemma_1b', token='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')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:34:47.350694Z","iopub.execute_input":"2025-04-09T10:34:47.350942Z","iopub.status.idle":"2025-04-09T10:34:50.986383Z","shell.execute_reply.started":"2025-04-09T10:34:47.350921Z","shell.execute_reply":"2025-04-09T10:34:50.985470Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/610 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d372fac0ae0d423c997f1d2a1ee1a69b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f918703f3aff43f5ac36f26da6c78bcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/26.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3380ea785664783b2100422f676bb31"}},"metadata":{}},{"name":"stdout","text":"Saved model to https://huggingface.co/davide710/pf_gemma_1b\n","output_type":"stream"},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"max_seq_length = 2048\ndtype = None\nload_in_4bit = True\n\nsaved, tokenizer = FastModel.from_pretrained(\n    model_name='davide710/pf_gemma_1b',\n    token='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',\n    max_seq_length=max_seq_length,\n    dtype=dtype,\n    load_in_4bit=load_in_4bit\n)\n\nprompt = \"\"\"Below is an instruction on how to translate text from complex and archaic to simple and modern english.\nThe input contains this text. Write in the response a faithful translation.\n\n### Instruction:\nTranslate the following line from complex to simple english.\nIt may contain archaic and literary words or structures: make them easily understandable.\n\n### Input:\n{}\n\n### Response:\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:36:33.978532Z","iopub.execute_input":"2025-04-09T10:36:33.978837Z","iopub.status.idle":"2025-04-09T10:36:48.412445Z","shell.execute_reply.started":"2025-04-09T10:36:33.978814Z","shell.execute_reply":"2025-04-09T10:36:48.411725Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.3.19: Fast Gemma3 patching. Transformers: 4.50.0.dev0. vLLM: 0.8.3.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post2. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\nUnsloth: Using float16 precision for gemma3 won't work! Using float32.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/26.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fff86ecf2b2a4ea1a61231c227704aa9"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"FastModel.for_inference(saved)\ninputs = tokenizer(\n[\n    prompt.format(\n        \"This above all: to thine own self be true, And it must follow, as the night the day,Thou canst not then be false to any man.\",\n#        \"This goodly frame, the earth, seems to me a sterile promontory, this most excellent canopy, the air, look you, this brave o'erhanging firmament, this majestical roof fretted with golden fire, why, it appears no other thing to me than a foul and pestilent congregation of vapours. What a piece of work is a man! how noble in reason! how infinite in faculty! in form and moving how express and admirable! in action how like an angel! in apprehension how like a god! the beauty of the world! the paragon of animals! And yet, to me, what is this quintessence of dust?\",    \n        \"\",\n    )\n], return_tensors=\"pt\").to(\"cuda\")\noutputs = saved.generate(\n    **inputs,\n    max_new_tokens=2048,\n    temperature=1.0, top_p=0.95, top_k=64,\n)\ntokenizer.batch_decode(outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:38:47.624642Z","iopub.execute_input":"2025-04-09T10:38:47.624977Z","iopub.status.idle":"2025-04-09T10:38:52.534305Z","shell.execute_reply.started":"2025-04-09T10:38:47.624954Z","shell.execute_reply":"2025-04-09T10:38:52.533453Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"[\"<bos>Below is an instruction on how to translate text from complex and archaic to simple and modern english.\\nThe input contains this text. Write in the response a faithful translation.\\n\\n### Instruction:\\nTranslate the following line from complex to simple english.\\nIt may contain archaic and literary words or structures: make them easily understandable.\\n\\n### Input:\\nThis above all: to thine own self be true, And it must follow, as the night the day,Thou canst not then be false to any man.\\n\\n### Response:\\nThis is the most important thing: be true to yourself. And it must follow the same rule as the night and the day: you can't be false to anyone.<end_of_turn>\"]"},"metadata":{}}],"execution_count":15}]}